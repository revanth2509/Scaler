{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2273291c210>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertConfig, BertForTokenClassification\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wnut(file_path):\n",
    "    file_path = Path(file_path)\n",
    "\n",
    "    raw_text = file_path.read_text().strip()\n",
    "    raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
    "    token_docs = []\n",
    "    tag_docs = []\n",
    "    for doc in raw_docs:\n",
    "        tokens = []\n",
    "        tags = []\n",
    "        for line in doc.split('\\n'):\n",
    "            token, tag = line.split('\\t')\n",
    "            tokens.append(token)\n",
    "            tags.append(tag)\n",
    "        token_docs.append(tokens)\n",
    "        tag_docs.append(tags)\n",
    "\n",
    "    return token_docs, tag_docs\n",
    "\n",
    "def get_dataframe(text,tags):\n",
    "    words = []\n",
    "    target = []\n",
    "    for sentence, tag in zip(text,tags):\n",
    "        for word in range(len(sentence)):\n",
    "            words.append(sentence[word])\n",
    "            target.append(tag[word])\n",
    "    data = pd.DataFrame(data={\"Words\":words,\"Tags\":target})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, tag = read_wnut(\"wnut 16.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@SammieLynnsMom', '@tg10781', 'they', 'will', 'be', 'all', 'done', 'by', 'Sunday', 'trust', 'me', '*wink*'] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "for text1, tags in zip(text,tag):\n",
    "    print(text1,tags)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, train_tags = read_wnut(\"wnut 16.txt\")\n",
    "test_text, test_tags = read_wnut(\"wnut 16test.txt\")\n",
    "train_data = get_dataframe(train_text,train_tags)\n",
    "test_data = get_dataframe(test_text,test_tags)\n",
    "\n",
    "train_data.to_csv(\"train.tsv\",sep=\"\\t\",index=False,header=True)\n",
    "test_data.to_csv(\"test.tsv\",sep=\"\\t\",index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@SammieLynnsMom</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@tg10781</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>will</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>be</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46464</th>\n",
       "      <td>whatchu</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46465</th>\n",
       "      <td>got</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46466</th>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46467</th>\n",
       "      <td>me</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46468</th>\n",
       "      <td>@kanyewest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Words Tags\n",
       "0      @SammieLynnsMom    O\n",
       "1             @tg10781    O\n",
       "2                 they    O\n",
       "3                 will    O\n",
       "4                   be    O\n",
       "...                ...  ...\n",
       "46464          whatchu    O\n",
       "46465              got    O\n",
       "46466              for    O\n",
       "46467               me    O\n",
       "46468       @kanyewest    O\n",
       "\n",
       "[46469 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the dataset:  10586\n"
     ]
    }
   ],
   "source": [
    "words = list(set(train_data[\"Words\"].values))\n",
    "n_words = len(words)\n",
    "print(\"Number of unique words in the dataset: \", n_words)\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "\n",
    "tags = list(set(train_data[\"Tags\"].values))\n",
    "label2idx = {t: i for i, t in enumerate(tags)}\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "label2idx[START_TAG] = 21\n",
    "label2idx[STOP_TAG] = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        # Matrix of transition parameters.  Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2))\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, sentence):\n",
    "        self.hidden = self.init_hidden()\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration0th and the loss tensor([57.1450], grad_fn=<SubBackward0>)\n",
      "Iteration1000th and the loss tensor([2.0627], grad_fn=<SubBackward0>)\n",
      "Iteration2000th and the loss tensor([0.2528], grad_fn=<SubBackward0>)\n",
      "tensor(5.8269)\n",
      "Iteration0th and the loss tensor([2.2906], grad_fn=<SubBackward0>)\n",
      "Iteration1000th and the loss tensor([0.2193], grad_fn=<SubBackward0>)\n",
      "Iteration2000th and the loss tensor([0.0815], grad_fn=<SubBackward0>)\n",
      "tensor(2.0242)\n",
      "Iteration0th and the loss tensor([0.1412], grad_fn=<SubBackward0>)\n",
      "Iteration1000th and the loss tensor([0.2069], grad_fn=<SubBackward0>)\n",
      "Iteration2000th and the loss tensor([0.0155], grad_fn=<SubBackward0>)\n",
      "tensor(0.6142)\n",
      "Iteration0th and the loss tensor([0.2774], grad_fn=<SubBackward0>)\n",
      "Iteration1000th and the loss tensor([0.0683], grad_fn=<SubBackward0>)\n",
      "Iteration2000th and the loss tensor([0.0090], grad_fn=<SubBackward0>)\n",
      "tensor(0.2749)\n",
      "Iteration0th and the loss tensor([0.0433], grad_fn=<SubBackward0>)\n",
      "Iteration1000th and the loss tensor([0.0195], grad_fn=<SubBackward0>)\n",
      "Iteration2000th and the loss tensor([0.0034], grad_fn=<SubBackward0>)\n",
      "tensor(0.1818)\n",
      "Iteration0th and the loss tensor([0.0272], grad_fn=<SubBackward0>)\n",
      "Iteration1000th and the loss tensor([0.0181], grad_fn=<SubBackward0>)\n",
      "Iteration2000th and the loss tensor([0.0030], grad_fn=<SubBackward0>)\n",
      "tensor(0.1415)\n",
      "Iteration0th and the loss tensor([0.0131], grad_fn=<SubBackward0>)\n",
      "Iteration1000th and the loss tensor([0.0171], grad_fn=<SubBackward0>)\n",
      "Iteration2000th and the loss tensor([0.0025], grad_fn=<SubBackward0>)\n",
      "tensor(0.1258)\n",
      "Iteration0th and the loss tensor([0.0095], grad_fn=<SubBackward0>)\n",
      "Iteration1000th and the loss tensor([0.0187], grad_fn=<SubBackward0>)\n",
      "Iteration2000th and the loss tensor([0.0019], grad_fn=<SubBackward0>)\n",
      "tensor(0.1129)\n",
      "Iteration0th and the loss tensor([0.0197], grad_fn=<SubBackward0>)\n",
      "Iteration1000th and the loss tensor([0.0139], grad_fn=<SubBackward0>)\n",
      "Iteration2000th and the loss tensor([0.0014], grad_fn=<SubBackward0>)\n",
      "tensor(0.1041)\n",
      "Iteration0th and the loss tensor([0.0137], grad_fn=<SubBackward0>)\n",
      "Iteration1000th and the loss tensor([0.0103], grad_fn=<SubBackward0>)\n",
      "Iteration2000th and the loss tensor([0.0016], grad_fn=<SubBackward0>)\n",
      "tensor(0.0924)\n",
      "(tensor(154.5079), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 1500\n",
    "HIDDEN_DIM = 1500\n",
    "\n",
    "\n",
    "model = BiLSTM_CRF(len(test_word2idx), label2idx, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
    "for epoch in range(10):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    losses = []\n",
    "    i = 0\n",
    "    for sentence, tags in zip(train_text, train_tags):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word2idx)\n",
    "        targets = torch.tensor([label2idx[t] for t in tags])\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        if i%1000 == 0:\n",
    "            print(f\"Iteration{i}th and the loss {loss}\")\n",
    "        i+=1\n",
    "    print(torch.tensor(losses).mean())\n",
    "\n",
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(train_text[0], word2idx)\n",
    "    print(model(precheck_sent))\n",
    "# We got it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(154.7276), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(train_text[0], word2idx)\n",
    "    print(model(precheck_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "transitions \t torch.Size([23, 23])\n",
      "word_embeds.weight \t torch.Size([18320, 1500])\n",
      "lstm.weight_ih_l0 \t torch.Size([3000, 1500])\n",
      "lstm.weight_hh_l0 \t torch.Size([3000, 750])\n",
      "lstm.bias_ih_l0 \t torch.Size([3000])\n",
      "lstm.bias_hh_l0 \t torch.Size([3000])\n",
      "lstm.weight_ih_l0_reverse \t torch.Size([3000, 1500])\n",
      "lstm.weight_hh_l0_reverse \t torch.Size([3000, 750])\n",
      "lstm.bias_ih_l0_reverse \t torch.Size([3000])\n",
      "lstm.bias_hh_l0_reverse \t torch.Size([3000])\n",
      "hidden2tag.weight \t torch.Size([23, 1500])\n",
      "hidden2tag.bias \t torch.Size([23])\n",
      "Optimizer's state_dict:\n",
      "state \t {0: {'momentum_buffer': None}, 1: {'momentum_buffer': None}, 2: {'momentum_buffer': None}, 3: {'momentum_buffer': None}, 4: {'momentum_buffer': None}, 5: {'momentum_buffer': None}, 6: {'momentum_buffer': None}, 7: {'momentum_buffer': None}, 8: {'momentum_buffer': None}, 9: {'momentum_buffer': None}, 10: {'momentum_buffer': None}, 11: {'momentum_buffer': None}}\n",
      "param_groups \t [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0.0001, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"LSTM_CRF1.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the dataset:  18320\n"
     ]
    }
   ],
   "source": [
    "words = list(set(test_data[\"Words\"].values))\n",
    "n_words = len(words)\n",
    "print(\"Number of unique words in the dataset: \", n_words)\n",
    "test_word2idx = {w: i for i, w in enumerate(words)}\n",
    "\n",
    "tags = list(set(test_data[\"Tags\"].values))\n",
    "test_label2idx = {t: i for i, t in enumerate(tags)}\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "test_label2idx[START_TAG] = 21\n",
    "test_label2idx[STOP_TAG] = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM_CRF(\n",
       "  (word_embeds): Embedding(18320, 1500)\n",
       "  (lstm): LSTM(1500, 750, bidirectional=True)\n",
       "  (hidden2tag): Linear(in_features=1500, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 1500\n",
    "HIDDEN_DIM = 1500\n",
    "model = BiLSTM_CRF(len(test_word2idx), label2idx, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "model.load_state_dict(torch.load(\"LSTM_CRF1.th\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8740)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    accuracy = 0\n",
    "    for text, tags in zip(test_text,test_tags):\n",
    "        postcheck_sent = torch.tensor([test_word2idx[w] for w in text])\n",
    "        postheck_tags = torch.tensor([test_label2idx[t] for t in tags], dtype=torch.long)\n",
    "        pred = model(postcheck_sent)\n",
    "        accuracy+=(postheck_tags == torch.tensor(pred[1])).sum()/len(postheck_tags)\n",
    "    print(accuracy/len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@SammieLynnsMom</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@tg10781</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>will</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>be</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Words Tags\n",
       "0  @SammieLynnsMom    O\n",
       "1         @tg10781    O\n",
       "2             they    O\n",
       "3             will    O\n",
       "4               be    O"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\", encoding='unicode_escape',index_col=[0])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags: 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tags\n",
       "O                44007\n",
       "B-person           449\n",
       "I-other            320\n",
       "B-geo-loc          276\n",
       "B-other            225\n",
       "I-person           215\n",
       "B-company          171\n",
       "I-facility         105\n",
       "B-facility         104\n",
       "B-product           97\n",
       "I-product           80\n",
       "I-musicartist       61\n",
       "B-musicartist       55\n",
       "B-sportsteam        51\n",
       "I-geo-loc           49\n",
       "I-movie             46\n",
       "I-company           36\n",
       "B-movie             34\n",
       "B-tvshow            34\n",
       "I-tvshow            31\n",
       "I-sportsteam        23\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of tags: {}\".format(len(data.Tags.unique())))\n",
    "frequencies = data.Tags.value_counts()\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-geo-loc': 1,\n",
       " 'B-facility': 2,\n",
       " 'I-facility': 3,\n",
       " 'B-movie': 4,\n",
       " 'I-movie': 5,\n",
       " 'B-company': 6,\n",
       " 'B-product': 7,\n",
       " 'B-person': 8,\n",
       " 'B-other': 9,\n",
       " 'I-other': 10,\n",
       " 'B-sportsteam': 11,\n",
       " 'I-sportsteam': 12,\n",
       " 'I-product': 13,\n",
       " 'I-company': 14,\n",
       " 'I-person': 15,\n",
       " 'I-geo-loc': 16,\n",
       " 'B-tvshow': 17,\n",
       " 'B-musicartist': 18,\n",
       " 'I-musicartist': 19,\n",
       " 'I-tvshow': 20}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {k: v for v, k in enumerate(data.Tags.unique())}\n",
    "id2label = {v: k for v, k in enumerate(data.Tags.unique())}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B-person', 449), ('I-other', 320), ('B-geo-loc', 276), ('B-other', 225), ('I-person', 215), ('B-company', 171), ('I-facility', 105), ('B-facility', 104), ('B-product', 97), ('I-product', 80), ('I-musicartist', 61), ('B-musicartist', 55), ('B-sportsteam', 51), ('I-geo-loc', 49), ('I-movie', 46), ('I-company', 36), ('B-movie', 34), ('B-tvshow', 34), ('I-tvshow', 31), ('I-sportsteam', 23)]\n"
     ]
    }
   ],
   "source": [
    "tags = {}\n",
    "for tag, count in zip(frequencies.index, frequencies):\n",
    "    if tag != \"O\":\n",
    "        if tag not in tags.keys():\n",
    "            tags[tag] = count\n",
    "        else:\n",
    "            tags[tag] += count\n",
    "    continue\n",
    "\n",
    "print(sorted(tags.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for text in train_text:\n",
    "    sentence = \"\"\n",
    "    for i in text:\n",
    "        sentence+=i+\" \"\n",
    "    sentences.append(sentence)\n",
    "total_tags = []\n",
    "for tags in train_tags:\n",
    "    tag = \"\"\n",
    "    for i in tags:\n",
    "        tag+=i + \",\"\n",
    "    total_tags.append(tag[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sentence\"] = pd.Series(sentences)\n",
    "data[\"label\"] = pd.Series(total_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"Words\",\"Tags\"],inplace=True,axis=1)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@SammieLynnsMom @tg10781 they will be all done...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Made it back home to GA . It sucks not to be a...</td>\n",
       "      <td>O,O,O,O,O,B-geo-loc,O,O,O,O,O,O,O,B-facility,I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>' Breaking Dawn ' Returns to Vancouver on Janu...</td>\n",
       "      <td>O,B-movie,I-movie,O,O,O,B-geo-loc,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ls_n perhaps , but folks may find something i...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Carr0t aye been tonight - excellent</td>\n",
       "      <td>O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>RT @MarioBB9 : Pope says atheists pick and cho...</td>\n",
       "      <td>O,O,O,B-person,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>Man I swear I bought 2 new outfits but it 's c...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>RT @ArtVanFurniture : Mr . Van sure is busy to...</td>\n",
       "      <td>O,O,O,B-person,I-person,I-person,O,O,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>@PersonalSelena can you follow me pretty pleas...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>good friday whatchu got for me @kanyewest</td>\n",
       "      <td>O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2394 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0     @SammieLynnsMom @tg10781 they will be all done...   \n",
       "1     Made it back home to GA . It sucks not to be a...   \n",
       "2     ' Breaking Dawn ' Returns to Vancouver on Janu...   \n",
       "3     @ls_n perhaps , but folks may find something i...   \n",
       "4                 @Carr0t aye been tonight - excellent    \n",
       "...                                                 ...   \n",
       "2389  RT @MarioBB9 : Pope says atheists pick and cho...   \n",
       "2390  Man I swear I bought 2 new outfits but it 's c...   \n",
       "2391  RT @ArtVanFurniture : Mr . Van sure is busy to...   \n",
       "2392  @PersonalSelena can you follow me pretty pleas...   \n",
       "2393         good friday whatchu got for me @kanyewest    \n",
       "\n",
       "                                                  label  \n",
       "0                               O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "1     O,O,O,O,O,B-geo-loc,O,O,O,O,O,O,O,B-facility,I...  \n",
       "2             O,B-movie,I-movie,O,O,O,B-geo-loc,O,O,O,O  \n",
       "3     O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "4                                           O,O,O,O,O,O  \n",
       "...                                                 ...  \n",
       "2389  O,O,O,B-person,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O...  \n",
       "2390              O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "2391  O,O,O,B-person,I-person,I-person,O,O,O,O,O,O,O...  \n",
       "2392                    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "2393                                      O,O,O,O,O,O,O  \n",
       "\n",
       "[2394 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "        sentence = self.data.sentence[index]  \n",
    "        word_labels = self.data.label[index]  \n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "        \n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        if (len(tokenized_sentence) > maxlen):\n",
    "          # truncate\n",
    "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
    "          labels = labels[:maxlen]\n",
    "        else:\n",
    "          # pad\n",
    "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "        \n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "        # the following line is deprecated\n",
    "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
    "        \n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (2394, 2)\n",
      "TRAIN Dataset: (1915, 2)\n",
      "TEST Dataset: (479, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([  101,  1030,  3565, 20147,  2064,  1045,  2131,  1037, 10474,  4007,\n",
       "          2000, 11867,  7974,  6721, 14636,  2055, 13586,  1013,  4157,  1013,\n",
       "          9281,  1029,  3426,  2008,  2052,  2489,  2039,  2070,  2051,  1012,\n",
       "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'targets': tensor([0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  1030,  3565, 20147,  2064,  1045,  2131,  1037, 10474,  4007,\n",
       "         2000, 11867,  7974,  6721, 14636,  2055, 13586,  1013,  4157,  1013,\n",
       "         9281,  1029,  3426,  2008,  2052,  2489,  2039,  2070,  2051,  1012,\n",
       "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0][\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]       O\n",
      "@           O\n",
      "super       O\n",
      "##anne      O\n",
      "can         O\n",
      "i           O\n",
      "get         O\n",
      "a           O\n",
      "twitter     B-company\n",
      "software    O\n",
      "to          O\n",
      "sp          O\n",
      "##ew        O\n",
      "random      O\n",
      "bullshit    O\n",
      "about       O\n",
      "airports    O\n",
      "/           O\n",
      "coffee      O\n",
      "/           O\n",
      "conferences  O\n",
      "?           O\n",
      "cause       O\n",
      "that        O\n",
      "would       O\n",
      "free        O\n",
      "up          O\n",
      "some        O\n",
      "time        O\n",
      ".           O\n"
     ]
    }
   ],
   "source": [
    "# print the first 30 tokens and corresponding labels\n",
    "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"ids\"][:30]), training_set[0][\"targets\"][:30]):\n",
    "  print('{0:10}  {1}'.format(token, id2label[label.item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=21, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', \n",
    "                                                   num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                   label2id=label2id)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9067, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
    "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
    "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "mask = mask.to(device)\n",
    "targets = targets.to(device)\n",
    "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 21])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_logits = outputs[1]\n",
    "tr_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "        \n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training loss per 100 training steps: 0.06929675489664078\n",
      "Training loss per 100 training steps: 0.053565228719835975\n",
      "Training loss per 100 training steps: 0.050586917432979564\n",
      "Training loss per 100 training steps: 0.04808246714304328\n",
      "Training loss per 100 training steps: 0.0475751140678622\n",
      "Training loss epoch: 0.04790579551093996\n",
      "Training accuracy epoch: 0.9590183286945262\n",
      "Training epoch: 2\n",
      "Training loss per 100 training steps: 0.04215997830033302\n",
      "Training loss per 100 training steps: 0.03712692446914492\n",
      "Training loss per 100 training steps: 0.03649516081187262\n",
      "Training loss per 100 training steps: 0.03590065079425582\n",
      "Training loss per 100 training steps: 0.03553006039181041\n",
      "Training loss epoch: 0.03396850670755905\n",
      "Training accuracy epoch: 0.9682017397128238\n",
      "Training epoch: 3\n",
      "Training loss per 100 training steps: 0.03562479838728905\n",
      "Training loss per 100 training steps: 0.025924439903920387\n",
      "Training loss per 100 training steps: 0.02644293190939213\n",
      "Training loss per 100 training steps: 0.025053960830824097\n",
      "Training loss per 100 training steps: 0.024339997132385424\n",
      "Training loss epoch: 0.024882503507400247\n",
      "Training accuracy epoch: 0.9753222433888027\n",
      "Training epoch: 4\n",
      "Training loss per 100 training steps: 0.0019726348109543324\n",
      "Training loss per 100 training steps: 0.01626833022161765\n",
      "Training loss per 100 training steps: 0.018292514582405526\n",
      "Training loss per 100 training steps: 0.018759091248375322\n",
      "Training loss per 100 training steps: 0.019167041538272776\n",
      "Training loss epoch: 0.01842798689761372\n",
      "Training accuracy epoch: 0.9816473252221113\n",
      "Training epoch: 5\n",
      "Training loss per 100 training steps: 0.0008706478402018547\n",
      "Training loss per 100 training steps: 0.018135244703372147\n",
      "Training loss per 100 training steps: 0.01588568390076007\n",
      "Training loss per 100 training steps: 0.014712965404815922\n",
      "Training loss per 100 training steps: 0.01425880267333583\n",
      "Training loss epoch: 0.013970131969924176\n",
      "Training accuracy epoch: 0.9860617081633083\n",
      "Training epoch: 6\n",
      "Training loss per 100 training steps: 0.021439671516418457\n",
      "Training loss per 100 training steps: 0.012446737448260704\n",
      "Training loss per 100 training steps: 0.010536172018335456\n",
      "Training loss per 100 training steps: 0.010129752745263997\n",
      "Training loss per 100 training steps: 0.010078357787369669\n",
      "Training loss epoch: 0.01022619594497089\n",
      "Training accuracy epoch: 0.9901233446605672\n",
      "Training epoch: 7\n",
      "Training loss per 100 training steps: 0.007052768487483263\n",
      "Training loss per 100 training steps: 0.007571113483155017\n",
      "Training loss per 100 training steps: 0.007643858531046316\n",
      "Training loss per 100 training steps: 0.007538463997610526\n",
      "Training loss per 100 training steps: 0.007384444169608407\n",
      "Training loss epoch: 0.007839718331509447\n",
      "Training accuracy epoch: 0.9932364386489853\n",
      "Training epoch: 8\n",
      "Training loss per 100 training steps: 0.0022671876940876245\n",
      "Training loss per 100 training steps: 0.0073342239847268426\n",
      "Training loss per 100 training steps: 0.006448446606912544\n",
      "Training loss per 100 training steps: 0.006033509025432207\n",
      "Training loss per 100 training steps: 0.005855275300752948\n",
      "Training loss epoch: 0.005983862560181655\n",
      "Training accuracy epoch: 0.9950161624421213\n",
      "Training epoch: 9\n",
      "Training loss per 100 training steps: 0.001748141017742455\n",
      "Training loss per 100 training steps: 0.004751914223174261\n",
      "Training loss per 100 training steps: 0.004747931765559227\n",
      "Training loss per 100 training steps: 0.005169166667882718\n",
      "Training loss per 100 training steps: 0.005119441130240343\n",
      "Training loss epoch: 0.005041133050732937\n",
      "Training accuracy epoch: 0.9960488598854534\n",
      "Training epoch: 10\n",
      "Training loss per 100 training steps: 0.00241595646366477\n",
      "Training loss per 100 training steps: 0.003791343578941991\n",
      "Training loss per 100 training steps: 0.004032732243533826\n",
      "Training loss per 100 training steps: 0.0038039785575050477\n",
      "Training loss per 100 training steps: 0.003909893949809914\n",
      "Training loss epoch: 0.004040137354147451\n",
      "Training accuracy epoch: 0.9962345635927358\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "            \n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    #print(eval_labels)\n",
    "    #print(eval_preds)\n",
    "\n",
    "    labels = [id2label[id.item()] for id in eval_labels]\n",
    "    predictions = [id2label[id.item()] for id in eval_preds]\n",
    "\n",
    "    #print(labels)\n",
    "    #print(predictions)\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.00020672072423622012\n",
      "Validation loss per 100 evaluation steps: 0.04670936920628814\n",
      "Validation loss per 100 evaluation steps: 0.04190672623143886\n",
      "Validation Loss: 0.04038859859538206\n",
      "Validation Accuracy: 0.9742906349364928\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     company       0.61      0.61      0.61        33\n",
      "    facility       0.71      0.35      0.47        43\n",
      "     geo-loc       0.56      0.91      0.69        45\n",
      "       movie       0.43      0.27      0.33        11\n",
      " musicartist       0.00      0.00      0.00        12\n",
      "       other       0.23      0.14      0.18        76\n",
      "      person       0.82      0.80      0.81       100\n",
      "     product       0.57      0.33      0.42        24\n",
      "  sportsteam       0.69      0.69      0.69        13\n",
      "      tvshow       0.30      0.25      0.27        12\n",
      "\n",
      "   micro avg       0.60      0.51      0.55       369\n",
      "   macro avg       0.49      0.44      0.45       369\n",
      "weighted avg       0.56      0.51      0.52       369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report([labels], [predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New</td>\n",
       "      <td>B-other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orleans</td>\n",
       "      <td>I-other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mother</td>\n",
       "      <td>I-other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'s</td>\n",
       "      <td>I-other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day</td>\n",
       "      <td>I-other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Words     Tags\n",
       "0      New  B-other\n",
       "1  Orleans  I-other\n",
       "2   Mother  I-other\n",
       "3       's  I-other\n",
       "4      Day  I-other"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test.csv\", encoding='unicode_escape',index_col=[0])\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for text in test_text:\n",
    "    sentence = \"\"\n",
    "    for i in text:\n",
    "        sentence+=i+\" \"\n",
    "    sentences.append(sentence)\n",
    "total_tags = []\n",
    "for tags in test_tags:\n",
    "    tag = \"\"\n",
    "    for i in tags:\n",
    "        tag+=i + \",\"\n",
    "    total_tags.append(tag[:-1])\n",
    "\n",
    "\n",
    "test_data[\"sentence\"] = pd.Series(sentences)\n",
    "test_data[\"label\"] = pd.Series(total_tags)\n",
    "test_data.drop([\"Words\",\"Tags\"],inplace=True,axis=1)\n",
    "test_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Orleans Mother 's Day Parade shooting . On...</td>\n",
       "      <td>B-other,I-other,I-other,I-other,I-other,I-othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @hxranspizza : Going into school tomorrow l...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>May e just a smile in your heart EILY Countdow...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,B-movie,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I could so do Thursday Club right now</td>\n",
       "      <td>O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@therealdaftbear Albert Nobbs ( Glenn Close)is...</td>\n",
       "      <td>O,B-person,I-person,O,B-person,O,O,O,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>Priest killed , another injured in US shooting...</td>\n",
       "      <td>O,O,O,O,O,O,B-geo-loc,O,O,B-geo-loc,I-geo-loc,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>Michael__Myerz : |LIVE NOW| Yes #meerkat https...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>http://t.co/MoMmuSaDKE Daily Fantasy Basketbal...</td>\n",
       "      <td>O,O,O,O,O,O,O,B-other,O,B-company,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>@Toniakins no man alive has it all . But you c...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>RT @NaddictsOfc : She 's living with her famil...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3850 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0     New Orleans Mother 's Day Parade shooting . On...   \n",
       "1     RT @hxranspizza : Going into school tomorrow l...   \n",
       "2     May e just a smile in your heart EILY Countdow...   \n",
       "3                I could so do Thursday Club right now    \n",
       "4     @therealdaftbear Albert Nobbs ( Glenn Close)is...   \n",
       "...                                                 ...   \n",
       "3845  Priest killed , another injured in US shooting...   \n",
       "3846  Michael__Myerz : |LIVE NOW| Yes #meerkat https...   \n",
       "3847  http://t.co/MoMmuSaDKE Daily Fantasy Basketbal...   \n",
       "3848  @Toniakins no man alive has it all . But you c...   \n",
       "3849  RT @NaddictsOfc : She 's living with her famil...   \n",
       "\n",
       "                                                  label  \n",
       "0     B-other,I-other,I-other,I-other,I-other,I-othe...  \n",
       "1                                 O,O,O,O,O,O,O,O,O,O,O  \n",
       "2                           O,O,O,O,O,O,O,O,B-movie,O,O  \n",
       "3                                       O,O,O,O,O,O,O,O  \n",
       "4     O,B-person,I-person,O,B-person,O,O,O,O,O,O,O,O...  \n",
       "...                                                 ...  \n",
       "3845  O,O,O,O,O,O,B-geo-loc,O,O,B-geo-loc,I-geo-loc,...  \n",
       "3846                        O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "3847      O,O,O,O,O,O,O,B-other,O,B-company,O,O,O,O,O,O  \n",
       "3848  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "3849                            O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "\n",
       "[3850 rows x 2 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = dataset(test_data, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([ 101, 2047, 5979, 2388, 1005, 1055, 2154, 7700, 5008, 1012, 2028, 1997,\n",
       "         1996, 2111, 3480, 2001, 1037, 2184, 1011, 2095, 1011, 2214, 2611, 1012,\n",
       "         2054, 1996, 3109, 2003, 3308, 2007, 2111, 1029,  102,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'targets': tensor([ 0,  9, 10, 10, 10, 10, 10, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0])}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = {'batch_size': 4,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.08591140806674957\n",
      "Validation loss per 100 evaluation steps: 0.103067406943635\n",
      "Validation loss per 100 evaluation steps: 0.10063853276601299\n",
      "Validation loss per 100 evaluation steps: 0.10158272669984196\n",
      "Validation loss per 100 evaluation steps: 0.09894667951045547\n",
      "Validation loss per 100 evaluation steps: 0.09846239740300497\n",
      "Validation loss per 100 evaluation steps: 0.0936237592795866\n",
      "Validation loss per 100 evaluation steps: 0.09177889410474357\n",
      "Validation loss per 100 evaluation steps: 0.09134200254667983\n",
      "Validation loss per 100 evaluation steps: 0.09140491785799615\n",
      "Validation Loss: 0.09194363826059972\n",
      "Validation Accuracy: 0.9513486634783093\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     company       0.64      0.41      0.50      1337\n",
      "    facility       0.21      0.14      0.17       390\n",
      "     geo-loc       0.47      0.60      0.53      1244\n",
      "       movie       0.16      0.05      0.07        66\n",
      " musicartist       0.47      0.02      0.04       326\n",
      "       other       0.28      0.18      0.22      1004\n",
      "      person       0.54      0.58      0.56       726\n",
      "     product       0.22      0.08      0.12       428\n",
      "  sportsteam       0.56      0.22      0.32       247\n",
      "      tvshow       0.14      0.06      0.08        71\n",
      "\n",
      "   micro avg       0.46      0.35      0.40      5839\n",
      "   macro avg       0.37      0.23      0.26      5839\n",
      "weighted avg       0.44      0.35      0.37      5839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report([labels], [predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"India has a capital called Mumbai. On wednesday, the president will give a presentation\"\n",
    "\n",
    "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "# move to gpu\n",
    "ids = inputs[\"input_ids\"].to(device)\n",
    "mask = inputs[\"attention_mask\"].to(device)\n",
    "# forward pass\n",
    "outputs = model(ids, mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[CLS]', 'O'),\n",
       " ('india', 'B-geo-loc'),\n",
       " ('has', 'O'),\n",
       " ('a', 'O'),\n",
       " ('capital', 'O'),\n",
       " ('called', 'O'),\n",
       " ('mumbai', 'B-geo-loc'),\n",
       " ('.', 'O'),\n",
       " ('on', 'O'),\n",
       " ('wednesday', 'O'),\n",
       " (',', 'O'),\n",
       " ('the', 'O'),\n",
       " ('president', 'O'),\n",
       " ('will', 'O'),\n",
       " ('give', 'O'),\n",
       " ('a', 'O'),\n",
       " ('presentation', 'O'),\n",
       " ('[SEP]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O')]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wp_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Tokenizer_Bert_Ner.th\\\\tokenizer_config.json',\n",
       " 'Tokenizer_Bert_Ner.th\\\\special_tokens_map.json',\n",
       " 'Tokenizer_Bert_Ner.th\\\\vocab.txt',\n",
       " 'Tokenizer_Bert_Ner.th\\\\added_tokens.json')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"Bert_Ner.th\")\n",
    "tokenizer.save_pretrained(\"Tokenizer_Bert_Ner.th\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
